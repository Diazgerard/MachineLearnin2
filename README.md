# ğŸ¤– Sistema de Control Gestual ASL - Machine Learning 2

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **sistema de control gestual inteligente** que utiliza el **Lenguaje de SeÃ±as Americano (ASL)** para controlar comandos de computadora en tiempo real. Combina tecnologÃ­as avanzadas de **Machine Learning**, **Computer Vision** y **interfaces grÃ¡ficas** para crear una experiencia de usuario innovadora y accesible.

## ğŸ¯ CaracterÃ­sticas Principales

### ğŸ–ï¸ **Reconocimiento de Gestos Dual**
- **Mano Izquierda**: Reconocimiento de letras ASL (A-Z) para ejecutar comandos
- **Mano Derecha**: Control del cursor y clicks del mouse
- **DetecciÃ³n en Tiempo Real**: ~120ms de respuesta para detecciÃ³n visual

### ğŸ® **Control por Comandos**
- **25 Comandos Configurables**: Desde acciones bÃ¡sicas hasta aplicaciones especÃ­ficas
- **Comando Protegido**: Letra X siempre ejecuta "Presionar ESC" (no editable)
- **Cooldown Inteligente**: 3 segundos entre ejecuciones para evitar activaciones accidentales

### ğŸ–¥ï¸ **Interfaz de ConfiguraciÃ³n Visual**
- **Drag & Drop**: Arrastra letras ASL a comandos especÃ­ficos
- **VisualizaciÃ³n de ImÃ¡genes**: Muestra las seÃ±as ASL reales para cada letra
- **ConfiguraciÃ³n Persistente**: Guarda y carga configuraciones en formato JSON
- **Control de Estado**: Botones se bloquean durante la ejecuciÃ³n del control gestual

### ğŸ” **Sistema de Recomendaciones**
- **Paneles Horizontales**: Muestra 2 recomendaciones al lado de la cÃ¡mara
- **ActualizaciÃ³n Inteligente**: Cambia recomendaciones solo cuando detecta una nueva seÃ±a
- **Feedback Visual**: InformaciÃ³n en tiempo real sobre gestos detectados

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### **Machine Learning & Computer Vision**
- **TensorFlow 2.19.1**: ClasificaciÃ³n de gestos ASL
- **MediaPipe**: DetecciÃ³n y tracking de manos en tiempo real
- **OpenCV**: Procesamiento de imÃ¡genes y video
- **NumPy**: Operaciones matemÃ¡ticas y manipulaciÃ³n de arrays

### **Interfaz GrÃ¡fica**
- **PySide6**: AplicaciÃ³n de configuraciÃ³n moderna con Qt6
- **Drag & Drop**: Interfaz intuitiva para asignaciÃ³n de comandos

### **AutomatizaciÃ³n del Sistema**
- **PyAutoGUI**: Control del mouse y acciones del sistema
- **keyboard**: EjecuciÃ³n de comandos de teclado y shortcuts
- **win32gui/win32con**: IntegraciÃ³n avanzada con Windows

## ğŸ“ Estructura del Proyecto

```
MachineLearnin2/
â”œâ”€â”€ ğŸ“„ app.py                      # Interfaz de configuraciÃ³n visual
â”œâ”€â”€ ğŸ“„ program.py                  # Motor principal de reconocimiento gestual
â”œâ”€â”€ ğŸ“„ configuracion_gestos.json   # ConfiguraciÃ³n de comandos personalizada
â”œâ”€â”€ ğŸ“„ requirements.txt            # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ pyrightconfig.json         # ConfiguraciÃ³n del linter Python
â”œâ”€â”€ ğŸ“ models/                     # Modelos de Machine Learning
â”œâ”€â”€ ğŸ“ Sign_Images/               # ImÃ¡genes de referencia ASL
â”‚   â”œâ”€â”€ A.jpeg                    # SeÃ±as A-Z del alfabeto ASL
â”‚   â”œâ”€â”€ B.jpeg
â”‚   â””â”€â”€ ... (Z.jpeg)
â””â”€â”€ ğŸ“ venv_ml2/                  # Entorno virtual Python
    â”œâ”€â”€ Scripts/
    â””â”€â”€ Lib/
```

## ğŸš€ Comandos Disponibles

| #  | Letra ASL | Comando | DescripciÃ³n |
|----|-----------|---------|-------------|
| 0  | A | Copiar | Ctrl+C |
| 1  | B | Pegar | Ctrl+V |
| 2  | C | Deshacer | Ctrl+Z |
| 3  | D | Rehacer | Ctrl+Y |
| 4  | E | Screenshot | Captura de pantalla |
| 5  | F | Screenshot Portapapeles | Print Screen |
| 6  | G | Cambiar Ventana | Alt+Tab |
| 7  | H | Buscar | Ctrl+F |
| 8  | I | Nueva PestaÃ±a | Ctrl+T |
| 9  | J | Cerrar PestaÃ±a | Ctrl+W |
| 10 | K | Subir Volumen | Volume Up |
| 11 | L | Bajar Volumen | Volume Down |
| 12 | M | Silenciar | Volume Mute |
| 13 | N | Abrir Bloc de Notas | notepad |
| 14 | O | Abrir Calculadora | calc |
| 15 | P | Abrir Explorador | explorer |
| 16 | Q | Escribir Texto | "Hola desde IA!" |
| 17 | R | Refrescar | F5 |
| 18 | S | Borrar | Delete |
| 19 | T | Scroll Arriba | Scroll Up |
| 20 | U | Scroll Abajo | Scroll Down |
| 21 | V | Abrir Chrome | start chrome |
| 22 | W | Abrir Excel | start excel |
| 23 | X | **Presionar ESC** | **ğŸ”’ PROTEGIDO** |
| 24 | Y | Abrir Word | start winword |

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### **Prerrequisitos**
- **Python 3.10+**
- **Webcam** funcionando
- **Windows 10/11** (optimizado para Windows)

### **1. Clonar el Repositorio**
```bash
git clone https://github.com/Diazgerard/MachineLearnin2.git
cd MachineLearnin2
```

### **2. Crear Entorno Virtual**
```bash
python -m venv venv_ml2
venv_ml2\Scripts\activate
```

### **3. Instalar Dependencias**
```bash
pip install -r requirements.txt
```

### **4. Verificar Estructura**
AsegÃºrate de que existan:
- `ğŸ“ Sign_Images/` con imÃ¡genes A.jpeg a Z.jpeg
- `ğŸ“ models/` con los archivos .h5 y .keras
- `ğŸ“„ configuracion_gestos.json`

## ğŸ® CÃ³mo Usar

### **1. Configurar Comandos**
```bash
# Activar entorno virtual
venv_ml2\Scripts\activate

# Abrir interfaz de configuraciÃ³n
python app.py
```

**En la interfaz:**
- ğŸ–±ï¸ **Arrastra letras** desde el panel izquierdo a los comandos deseados
- ğŸ’¾ **Guarda la configuraciÃ³n** con el botÃ³n "Guardar configuraciÃ³n"
- ğŸš€ **Inicia el control gestual** con "Iniciar Control Gestual"

### **2. Control Gestual en Tiempo Real**
```bash
# O ejecutar directamente
python program.py
```

**Durante el uso:**
- ğŸ¤š **Mano Izquierda**: Hacer seÃ±as ASL para ejecutar comandos
- ğŸ–±ï¸ **Mano Derecha**: Mover cursor en el rectÃ¡ngulo azul
- ğŸ‘† **Dedo Ãndice Abajo**: Click del mouse
- âŒ¨ï¸ **ESC**: Salir del programa

### **3. Paneles de InformaciÃ³n**
El sistema muestra en tiempo real:
- ğŸ“Š **Estado**: Configuraciones cargadas, Ãºltimo comando ejecutado
- â±ï¸ **Cooldown**: Tiempo restante antes del prÃ³ximo comando
- ğŸ” **DetecciÃ³n**: Letra detectada con nivel de confianza
- ğŸ’¡ **Recomendaciones**: Sugerencias de seÃ±as disponibles

## âš™ï¸ ConfiguraciÃ³n Avanzada

### **Ajustar Tiempos de Respuesta**
En `program.py`, lÃ­nea ~228:
```python
EXEC_COOLDOWN = 3.0  # Segundos entre comandos (ajustable)
```

### **Modificar Confianza de DetecciÃ³n**
En `program.py`, funciÃ³n `main()`:
```python
min_detection_confidence=0.5  # 0.1 (mÃ¡s sensible) a 0.9 (mÃ¡s estricto)
```

### **Personalizar Comandos**
Edita la funciÃ³n `actions` en `program.py` para agregar comandos personalizados:
```python
"Mi Comando": lambda: os.system("mi_aplicacion.exe"),
```

## ğŸ”¬ Arquitectura TÃ©cnica

### **Flujo de Procesamiento**
1. **Captura de Video** â†’ OpenCV + DirectShow
2. **DetecciÃ³n de Manos** â†’ MediaPipe (50% confianza mÃ­nima)
3. **ExtracciÃ³n de Landmarks** â†’ 21 puntos de referencia por mano
4. **ClasificaciÃ³n ASL** â†’ TensorFlow CNN (~75ms)
5. **EjecuciÃ³n de Comando** â†’ PyAutoGUI/keyboard
6. **Feedback Visual** â†’ OpenCV + Recomendaciones

### **Modelos de IA**
- **Modelo Principal**: `asl_alphabet_model.h5`
- **Modelo Alternativo**: `EfficientNetB5_gesture_classifier.keras`
- **Entrada**: Landmarks de mano (21 puntos x,y,z)
- **Salida**: ClasificaciÃ³n A-Z (26 clases)

## ğŸš¨ SoluciÃ³n de Problemas

### **Error: "No se encuentra el modelo"**
```bash
# Verificar que el archivo existe
dir models\*.h5
dir models\*.keras
```

### **Error: "CÃ¡mara no detectada"**
- Verificar que la webcam estÃ© conectada
- Cerrar otras aplicaciones que usen la cÃ¡mara
- Cambiar el Ã­ndice de cÃ¡mara en `program.py`:
```python
cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)  # Cambiar 0 por 1
```

### **Error: "Dependencias faltantes"**
```bash
# Reinstalar dependencias
pip install --force-reinstall -r requirements.txt
```

### **Gestos no se detectan bien**
- ğŸŒŸ **IluminaciÃ³n**: Usar buena iluminaciÃ³n frontal
- ğŸ“ **Distancia**: Mantener la mano a 30-60cm de la cÃ¡mara
- ğŸ¤š **Claridad**: Hacer gestos ASL claros y definidos
- â±ï¸ **Tiempo**: Mantener la seÃ±a por 1-2 segundos

